# Emotion-Recognition-using-images-and-audio
Overview:
Feelings are essential to human conversation, and the capability to suitably understand and classify them from facial expressions and audio signal is of outstanding significance in several domains, which includes human-computer interaction, healthcare, and leisure. In reaction to this, we present a complete progress that holds advanced deep studying strategies to construct an Emotion recognition machine able to real-time analysis and prediction of human feelings. To attain this, researchers have employed various strategies, such as machine learning, deep learning, and computer vision. Facts-driven methods contain the collection of large datasets of facial expressions annotated with corresponding emotions, which serve as the foundation for training and evaluating emotion recognition models. Deep getting to know models, such as convolutional neural networks (CNNs) and recurrent neural networks (RNNs), have shown extremely good achievement in taking pictures complicated facial emotions and temporal dynamics, resulting in advanced recognition accuracy. Dataset:

Facial Emotion Recognition The facial emotion recognition dataset contains 7 emotion types. The dataset contains 35,685 examples of 48x48 pixel gray scale images. These images are divided into train and test dataset. Images are categorized based on the emotion in the facial expression.

7 Emotion Types: • Happiness • Neutral • Sadness • Anger • Surprise • Disgust • Fear

Audio Emotion Recognition The dataset used for audio emotion recognition is Toronto emotional speech set (TESS).This dataset is only female actor and is of very high quality audio. Most of the other dataset is skewed closer to male audio System and thus brings about a slightly imbalance representation. So because of that, this dataset would serve a very good training dataset for the emotion classifier in terms of generalization (not overfitting). There are a set of 200 target words were spoken in this dataset and recordings were made of the set portraying each of seven emotion types (happiness, anger, sadness, disgust, neutral, surprise and fear). There are 2800 audio files in this dataset. The dataset is organized such that each of the two female actor and their emotions are contain within its own folder. And within that, all 200 target words audio file can be found. The format of the audio file is a WAV format.
Experimentation and results:
For emotion detection for facial expressions, data was collected from 50 subjects for testing. Then, the  accuracy was found at 100 epochs for image classification is 80%. The accuracy was found at 100 epochs for video classification is 100%.
Conclusion:
Based on the emotion detection analysis processed the image and audio classification,the accuarcy obtained for image classification was 80% and for audio classification was 100%.So emotion recognition using audio is suggested based on the analysis.


